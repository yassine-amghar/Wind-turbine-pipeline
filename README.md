# Wind-turbine-pipeline
Les données proviennent de trois turbines éoliennes, T101, T102 et T103, simulées via des générateurs Python qui publient les informations sur des topics MQTT spécifiques à chaque turbine. Ces flux sont centralisés par un broker MQTT Mosquitto, qui gère les communications en temps réel pour chaque topic wind/turbine/data/T101, T102 et T103. Ensuite, un Nœud 1 collecte et nettoie ces données : un subscriber MQTT écoute simultanément les trois topics, les valeurs manquantes sont remplacées et la validité des données est vérifiée. Les données propres sont transmises au Nœud 2, un système Redis Pub/Sub, qui distribue les flux en temps réel sur trois channels dédiés à chaque turbine et assure le transfert vers la base MongoDB. Le Nœud 3 gère le stockage dans MongoDB, dans la collection turbine_data, avec un index sur (turbine_id, timestamp), permettant un archivage long terme distribué par turbine. Enfin, un moteur de requêtes permet de calculer et suivre des KPIs essentiels, tels que la vitesse moyenne du vent, l’efficacité de production, la production d’énergie quotidienne et le total d’énergie exportée.

- Collecte et Nettoyage des Données (Nœud 1)
Le premier nœud agit comme point d'entrée du système. Il s'abonne aux trois topics MQTT (wind/turbine/data/T101, T102, T103) et reçoit les messages JSON générés par les éoliennes. Chaque message contient la vitesse du vent, la puissance produite et l'énergie exportée. Le nœud effectue un nettoyage essentiel des données en détectant et remplaçant les valeurs NaN ou invalides par null, conformément aux exigences du projet. Cette étape garantit l'intégrité des données avant leur transmission. Une fois nettoyées, les données sont enrichies avec un timestamp de traitement et publiées vers le système de streaming Redis.

- Distribution via Redis Pub/Sub (Nœud 2)
Le deuxième nœud implémente un système de streaming basé sur Redis Pub/Sub, une technologie NoSQL conforme aux contraintes du projet. Trois canaux Redis sont créés, un par éolienne (turbine:stream:T101, T102, T103), permettant une distribution logique des données par source. Ce nœud s'abonne à ces canaux et agit comme passerelle entre le flux temps réel et le stockage persistant. Cette architecture permet de séparer les responsabilités : le traitement en streaming reste léger et réactif, tandis que la persistance est déléguée à MongoDB. La distribution des données par canal Redis démontre clairement le principe de répartition demandé dans le projet, chaque turbine ayant son propre flux indépendant.

- Stockage et Requêtes (Nœud 3)
Le troisième nœud gère le stockage long terme dans MongoDB avec une collection turbine_data indexée sur (turbine_id, timestamp) pour optimiser les requêtes temporelles. Le principe de distribution est implémenté via une stratégie de sharding conceptuelle par turbine_id, où chaque éolienne peut être considérée comme une partition logique des données. Le moteur de requêtes exploite les capacités d'agrégation de MongoDB pour calculer les quatre KPIs demandés : vitesse moyenne du vent par éolienne (via $avg), efficacité de production calculée comme ratio puissance/vitesse (via $divide et $avg), production d'énergie quotidienne par groupement de dates (via $group et $sum), et total d'énergie exportée cumulée pour l'ensemble du parc. Les index permettent des requêtes rapides même sur de grands volumes de données historiques.
